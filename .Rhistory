n_estimates_tot    <- c(n_estimates_tot, nrow(db_i_tot) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_2 <- data.frame(Impact = levels(db$Impact), n_studies, n_estimates_testing, n_estimates_tot, perc_testing, usable, unusable, perc_usable)
Table_2[is.na(Table_2)] <- 0
colnames(Table_2) <- c("Impact", "N° studies", "N° interventions testing","N° interventions tot", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_2,"Tables/Table_2.csv")
#Redefining levels
levels(db$Impact)[2] <- "Multiple"
levels(db$Conservation_Action)[5] <- "Gating"
###############################################################
## Meta-Analysis
###############################################################
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
mean(table(db_metafor$ID)) ; sd(table(db_metafor$ID))
dim(db_metafor)
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Genus_specific,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- metafor::escalc(measure = "COR", ri = r, ni = N, data = db_metafor)
str(db)
db_full <-
read.csv(
file = "Data/Master_Database_Cave_Conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
db_full <- db_full[db_full$Remove != "yes",] ; db_full <- droplevels(db_full)
db$Pearson.s_r <- as.numeric(db$Pearson.s_r)
#Database only with distinct paper
db_full_unique <- distinct(db_full, ID, .keep_all = TRUE)
nrow(db_full)
nrow(db_full_unique)
#Subselecting BAT studies
db <- db_full[db_full$Bat_analysis == "yes",] ; db <- droplevels(db)
db$N <- as.numeric(db$N)
#
db_unique <- distinct(db, ID, .keep_all = TRUE)
nrow(db_unique)
nrow(db)
table(db_unique$Database)
table(db_unique$Publication_type)
rm(list = ls())
source("Functions/Functions_bat.R")
###############################################################
## Data preparation:
###############################################################
# Loading the Database ----------------------------------------------------
db_full <-
read.csv(
file = "Data/Master_Database_Cave_Conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
# Removing duplicates
db_full <- db_full[db_full$Remove != "yes",] ; db_full <- droplevels(db_full)
#Database only with distinct paper
db_full_unique <- distinct(db_full, ID, .keep_all = TRUE)
nrow(db_full)
nrow(db_full_unique)
#Subselecting BAT studies
db <- db_full[db_full$Bat_analysis == "yes",] ; db <- droplevels(db)
db$Pearson.s_r <- as.numeric(db$Pearson.s_r)
db$N <- as.numeric(db$N)
#
db_unique <- distinct(db, ID, .keep_all = TRUE)
nrow(db_unique)
nrow(db)
table(db_unique$Database)
table(db_unique$Publication_type)
# How many study consider bats and other groups?
a <- ifelse(table(db$ID, db$Taxon_Group)>0,1,0)
table(rowSums(a))
sum(table(rowSums(a))[c(2,3)])/sum(table(rowSums(a)))*100 #4.06 % of studies consider multiple organisms
# Selecting only bats
db <- db[db$Taxon_Group == "Bats",] ; db <- droplevels(db)
#Checking levels of factors
levels(db$Genus_specific)
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Type of actions
table(db$Publication_type)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies            <- c()
n_estimates_testing  <- c()
n_estimates_tot      <- c()
perc_testing         <- c()
usable               <- c()
unusable             <- c()
perc_usable          <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates_testing    <- c(n_estimates_testing, nrow(db_i) ) #unique estimates
n_estimates_tot    <- c(n_estimates_tot, nrow(db_i_tot) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_1 <- data.frame(Intervention = levels(db$Conservation_Action), n_studies, n_estimates_testing, n_estimates_tot, perc_testing, usable, unusable, perc_usable)
Table_1[is.na(Table_1)] <- 0
colnames(Table_1) <- c("Intervention", "N° studies", "N° interventions testing","N° interventions tot", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_1,"Tables/Table_1.csv")
#How many estimates would be usable for meta analysis?
n_studies            <- c()
n_estimates_testing  <- c()
n_estimates_tot      <- c()
perc_testing         <- c()
usable               <- c()
unusable             <- c()
perc_usable          <- c()
for(i in 1:nlevels(db$Impact)){
db_i_tot <- db[db$Impact == levels(db$Impact)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates_testing    <- c(n_estimates_testing, nrow(db_i) ) #unique estimates
n_estimates_tot    <- c(n_estimates_tot, nrow(db_i_tot) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_2 <- data.frame(Impact = levels(db$Impact), n_studies, n_estimates_testing, n_estimates_tot, perc_testing, usable, unusable, perc_usable)
Table_2[is.na(Table_2)] <- 0
colnames(Table_2) <- c("Impact", "N° studies", "N° interventions testing","N° interventions tot", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_2,"Tables/Table_2.csv")
#Redefining levels
levels(db$Impact)[2] <- "Multiple"
levels(db$Conservation_Action)[5] <- "Gating"
###############################################################
## Meta-Analysis
###############################################################
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
mean(table(db_metafor$ID)) ; sd(table(db_metafor$ID))
dim(db_metafor)
nlevels(db_metafor$ID)
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Genus_specific,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
str(db)
db_metafor <- metafor::escalc(measure = "COR", ri = r, ni = N, data = db_metafor)
###############################################################
## Let's not wing it: Practical conservation of subterranean-roosting bats
## Meierhofer M., et al.
## ------------------------------------------------------------------------
# 'R script to reproduce the analyses'
## ------------------------------------------------------------------------
# Analysis performed with R (v. R 4.1.0) and R studio (v. 1.4.1103)
# Authors (code): Stefano Mammola & Melissa B. Meierhofer
###############################################################
# clean the workspace -----------------------------------------------------
rm(list = ls())
# Loading R package -------------------------------------------------------
library("metafor")   # Meta-Analysis Package for R
library("ggplot2")
library("ggraph")
library("igraph")
library("tidygraph")
library("tidyverse")
# Sourcing useful functions ------------------------------------------------
source("Functions/Functions_bat.R")
###############################################################
## Data preparation:
###############################################################
# Loading the Database ----------------------------------------------------
db_full <-
read.csv(
file = "Data/Master_Database_Cave_Conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
# Removing duplicates
db_full <- db_full[db_full$Remove != "yes",] ; db_full <- droplevels(db_full)
#Database only with distinct paper
db_full_unique <- distinct(db_full, ID, .keep_all = TRUE)
nrow(db_full)
nrow(db_full_unique)
#Subselecting BAT studies
db <- db_full[db_full$Bat_analysis == "yes",] ; db <- droplevels(db)
db$Pearson.s_r <- as.numeric(db$Pearson.s_r)
db$N <- as.numeric(db$N)
#
db_unique <- distinct(db, ID, .keep_all = TRUE)
nrow(db_unique)
nrow(db)
table(db_unique$Database)
table(db_unique$Publication_type)
# How many study consider bats and other groups?
a <- ifelse(table(db$ID, db$Taxon_Group)>0,1,0)
table(rowSums(a))
sum(table(rowSums(a))[c(2,3)])/sum(table(rowSums(a)))*100 #4.06 % of studies consider multiple organisms
# Selecting only bats
db <- db[db$Taxon_Group == "Bats",] ; db <- droplevels(db)
#Checking levels of factors
levels(db$Genus_specific)
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Type of actions
table(db$Publication_type)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies            <- c()
n_estimates_testing  <- c()
n_estimates_tot      <- c()
perc_testing         <- c()
usable               <- c()
unusable             <- c()
perc_usable          <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates_testing    <- c(n_estimates_testing, nrow(db_i) ) #unique estimates
n_estimates_tot    <- c(n_estimates_tot, nrow(db_i_tot) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_1 <- data.frame(Intervention = levels(db$Conservation_Action), n_studies, n_estimates_testing, n_estimates_tot, perc_testing, usable, unusable, perc_usable)
Table_1[is.na(Table_1)] <- 0
colnames(Table_1) <- c("Intervention", "N° studies", "N° interventions testing","N° interventions tot", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_1,"Tables/Table_1.csv")
#How many estimates would be usable for meta analysis?
n_studies            <- c()
n_estimates_testing  <- c()
n_estimates_tot      <- c()
perc_testing         <- c()
usable               <- c()
unusable             <- c()
perc_usable          <- c()
for(i in 1:nlevels(db$Impact)){
db_i_tot <- db[db$Impact == levels(db$Impact)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates_testing    <- c(n_estimates_testing, nrow(db_i) ) #unique estimates
n_estimates_tot    <- c(n_estimates_tot, nrow(db_i_tot) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_2 <- data.frame(Impact = levels(db$Impact), n_studies, n_estimates_testing, n_estimates_tot, perc_testing, usable, unusable, perc_usable)
Table_2[is.na(Table_2)] <- 0
colnames(Table_2) <- c("Impact", "N° studies", "N° interventions testing","N° interventions tot", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_2,"Tables/Table_2.csv")
#Redefining levels
levels(db$Impact)[2] <- "Multiple"
levels(db$Conservation_Action)[5] <- "Gating"
###############################################################
## Meta-Analysis
###############################################################
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
mean(table(db_metafor$ID)) ; sd(table(db_metafor$ID))
dim(db_metafor)
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Genus_specific,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- metafor::escalc(measure = "COR", ri = r, ni = N, data = db_metafor)
# Gate
db_metafor <- db_metafor[db_metafor$Predictor_Group == "Gate" |
db_metafor$Predictor_Group == "Disturbance reduction" |
db_metafor$Predictor_Group == "Restoration" |
db_metafor$Predictor_Group == "Decontamination" |
db_metafor$Predictor_Group == "Monitoring", ] ; db_metafor <- droplevels(db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
db_metafor <- db_metafor[!c(db_metafor$Predictor_Group == "Disturbance reduction" & db_metafor$Response_Group == "Population"),]
db_metafor <- db_metafor[!c(db_metafor$Predictor_Group == "Monitoring" & db_metafor$Response_Group == "Pathogen"),]
#Check sample size for each predictors
table_n <- data.frame(predictor = NULL, n = NULL, n_papers = NULL)
for(i in 1:length(unique(levels(db_metafor$Response_Group))))
table_n <- rbind(table_n,
data.frame(predictor = levels(db_metafor$Response_Group)[i],
n = nrow(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]),
n_papers = length(unique(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]$ID)))
)
actions_to_analyse    <- c("Decontamination", "Disturbance reduction", "Gate", "Monitoring", "Restoration")
SUBSET      <- list()
MODEL       <- list()
result_for_plot <- data.frame(label_action = NULL,
label_pred = NULL,
size = NULL,
b     = NULL,
beta  = NULL,
se    = NULL,
z = NULL,
p     = NULL,
ci.lb = NULL,
ci.ub = NULL,
ES    = NULL,
L     = NULL,
U     = NULL,
failsafe_N = NULL,
failsafe_p = NULL)
num <- 0
# Modelling
for (j in 1:length(actions_to_analyse)){
data_j  <- db_metafor[db_metafor$Predictor_Group == actions_to_analyse[j], ] ; data_j <- droplevels(data_j)
predictors_to_analyse <- levels(data_j$Response_Group)
for (i in 1:length(predictors_to_analyse)){
#subset the predictor
data_i  <- data_j[data_j$Response_Group == predictors_to_analyse[i], ]
if(nrow(data_i)<2) { NULL } else {
#fitting the model
model_i  <- rma.mv(yi, vi, random =  ~ 1 | ID, data = na.omit(data_i))
failsafe_i <- fsn(yi, vi, type = "Rosenthal", data = na.omit(data_i))
#extracting coefficients
result_for_plot_i <- data.frame(label_action =  actions_to_analyse[j],
label_pred = paste(predictors_to_analyse[i]," (" ,
nrow(data_i),", ",
length(unique(data_i$ID)),")",sep=''),
size = length(unique(data_i$ID)),
b     = model_i$b,
beta  = round(model_i$beta[1],3),
se    = round(model_i$se[1],3),
z      = round(model_i$zval[1],3),
p     = round(model_i$pval[1],3),
ci.lb = round(model_i$ci.lb,3),
ci.ub = round(model_i$ci.ub,3),
ES    = ((exp(model_i$b)-1))/((exp(model_i$b)+1)),
L     = ((exp(model_i$ci.lb)-1)/(exp(model_i$ci.lb)+1)),
U     = ((exp(model_i$ci.ub)-1)/(exp(model_i$ci.ub)+1)),
failsafe_N = failsafe_i$fsnum,
failsafe_p = round(failsafe_i$pval,3)
)
#store the data
SUBSET[[j - 1 + num + i]]     <- data_i
MODEL[[j - 1 + num + i]]      <- model_i
result_for_plot <- rbind(result_for_plot,result_for_plot_i)
}}
num <- length(MODEL) - j
}
ros_N <- c()
ros   <- c()
for (i in 1 : length(SUBSET)){
Ros_i <- fsn(yi, vi, type = "Rosenthal", data = SUBSET[[i]])
ros_N <- c(ros_N,Ros_i$fsnum)
ros   <- c(ros,round(Ros_i$pval,3))
message(paste("---",  SUBSET[[i]]$Predictor_Group[1], "---",  SUBSET[[i]]$new_name[1],  sep = ' '))
print(Ros_i) #Rosenthal's failsafe number (rule-of-thumb: it should be larger than n*5 + 10)
}
rownames(result_for_plot) <- NULL
ORDER <- as.character(result_for_plot$label_pred)
result_for_plot$label_pred <- factor(result_for_plot$label_pred, ORDER) #sort
table_3 <- result_for_plot %>% dplyr::select(label_action, label_pred, beta, se, ci.lb, ci.ub, z, p, failsafe_N, failsafe_p)
table_3$ci.lb <- paste0("[",table_3$ci.lb, " — ",table_3$ci.ub, "]")
table_3$beta <-  paste0(table_3$beta, " +/- ", table_3$se)
table_3 <- table_3 %>% dplyr::select(-c(se,ci.ub))
table_3$failsafe_p <- rep("<0.001",nrow(table_3))
colnames(table_3) <- c("Conservation action",
"Response",
"Beta +/- SE", "95% CI", "z", "p", "failsafe [N]", "failsafe [p]")
write.table(table_3, "Tables/Table_3.csv", append = FALSE, sep = "\t", dec = ".")
#Converting multiple families as multiple
genus_split <- strsplit(as.character(db_metafor$Genus_specific), ";")
genus <- c()
for(i in 1:length(genus_split))
genus <- c(genus, ifelse(length(genus_split[[i]]) > 1, "Multiple", genus_split[[i]]) )
db_metafor$Genus_specific <- genus
# renaming Response group as in the result_for_plot
new_name <- factor(paste(db_metafor$Predictor_Group, db_metafor$Response_Group))
levels(new_name) <- ORDER
db_metafor <- data.frame(db_metafor,new_name)
colnames(db_metafor)
db_metafor$Genus_specific <- as.factor(db_metafor$Genus_specific)
db_metafor$Genus_specific <- relevel(db_metafor$Genus_specific , ref = "Multiple")
(meta_analysis <- ggplot(data= result_for_plot) +
geom_hline(yintercept = 0, lty = 2, col = "grey50") +  # add a dotted line at x=1 after flip
xlab("")+
ylab("Effect size [r]")+
geom_jitter(data = db_metafor, aes(x = new_name, y = r, shape = Genus_specific, col = Predictor_Group),
size = 1.5, width = 0.2, aplha =0.8)+
geom_pointrange(aes(x = label_pred, y = ES, ymin = L, ymax = U, col = label_action), size = 1) +
scale_color_manual("Conservation action", values = c("darkmagenta","grey10","darkcyan", "darkorange", "blue"))+
scale_shape_manual("Taxon", values = c(1:8))+
coord_flip() +
theme_custom() + theme(legend.position = "right",
legend.direction = "vertical",
legend.title = element_text(size = 12, face = "bold"),
axis.text.y = element_text(face= c("plain","plain","bold","plain","bold", "plain", "plain")))) # flip coordinates (puts labels on y axis)
#Save figure
pdf(file = "Figure/Figure_3.pdf", width = 9, height =5)
meta_analysis
dev.off()
# Action by region
COL =  c("grey20","darkorange")
geo_action <- semi_colon_splitter3(input1 = db$Higher_Geography,
input2 = db$Conservation_Action,
input3 = db$Tested_statistically,
names = c("Geography","Action","Test")
)
geo_action <- na.omit(geo_action)
bar_1 <- data.frame(table(geo_action$Geography,geo_action$Action,geo_action$Test))
colnames(bar_1) <- c("geo","action","test","N")
bar_1 <- bar_1[bar_1$geo != "Global",] ; bar_1 <- droplevels(bar_1)
bar_1$action <- factor(bar_1$action,levels =
c("Assessment", "Education","Legislation","Monitoring","Prioritization",
"Risk assessment",
"Decontamination","Eradication","Gating",
"Habitat creation","Habitat restoration",
"Protected area",  "Regulate access"
))
(bar_p1 <-  ggplot(bar_1, aes(x = action, y = N, fill = test)) +
facet_wrap( ~ geo, nrow = 2, ncol = 3) +
geom_bar(stat="identity",position= "stack", color = "grey10")+
scale_fill_manual("",labels=c("Not tested", "Tested"),values = COL)+
labs(title=NULL, subtitle = NULL,x=NULL, y = "Frequency")+
geom_vline(xintercept = 6.5, linetype="dotted",
color = "grey40", size=0.4)+
theme_custom()+
theme(legend.position =  "bottom",
axis.text.x = element_text(angle = 0, vjust = 1, hjust=1),
plot.margin = unit(c(0.2,0.2,0.2,0.2), 'cm'),
strip.text.x=element_text(color = "grey10", face = "bold", size=12),
strip.background = element_rect(colour=NA, fill=NA)
) + coord_flip()
)
# Action by region
geo_impact <- semi_colon_splitter3(input1 = db$Higher_Geography,
input2 = db$Impact,
input3 = db$Tested_statistically,
names = c("Geography","Impact","Test")
)
geo_impact <- na.omit(geo_impact)
bar_2 <- data.frame(table(geo_impact$Geography,geo_impact$Impact, geo_impact$Test))
colnames(bar_2) <- c("geo","Impact","test", "N")
bar_2 <- bar_2[bar_2$geo != "Global",] ; bar_2 <- droplevels(bar_2)
bar_2$Impact <- factor(bar_2$Impact,levels =
c("None identified",
"Multiple",
"Alien species",
"Climate change",
"Pathogen",
"Poaching",
"Pollution",
"Subterranean habitat change",
"Surface habitat change",
"Visitors"))
(bar_p2 <-  ggplot(bar_2, aes(x = Impact, y = N, fill = test)) +
facet_wrap( ~ geo, nrow = 2, ncol = 3) +
scale_fill_manual("",labels=c("Not tested", "Tested"),values = COL)+
geom_bar(stat="identity",position= "stack", color = "grey10")+
labs(title=NULL, subtitle = NULL,x=NULL, y = "Frequency")+
theme_custom()+
theme(legend.position =  "bottom",
axis.text.x = element_text(angle = 0, vjust = 1, hjust=1),
plot.margin = unit(c(0.2,0.2,0.2,0.2), 'cm'),
strip.text.x=element_text(color = "grey10", face = "bold", size=12),
strip.background = element_rect(colour=NA, fill=NA)) + coord_flip()
)
