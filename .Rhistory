rm(list = ls())
library("circlize")
library("cowplot")
library("dplyr")
library("ggplot2")
library("ggpubr")
library("grid")
library("gridExtra")
library("maps")
library("rsq")
library("parameters")
library("performance")
library("scatterpie")
library("tidyr")
source("/Functions/Functions_bat.R")
source("Functions/Functions_bat.R")
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
dec = '.',
header = TRUE,
as.is = FALSE
)
#Database only with distinct paper
db_unique <- distinct(db, ID, .keep_all = TRUE)
#Checking levels of factors
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Taxon_Group)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
source("Functions/Functions_bat.R")
source("Functions/Functions_bat.R")
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies    <- c()
n_estimates  <- c()
perc_testing <- c()
usable       <- c()
unusable     <- c()
perc_usable  <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates    <- c(n_estimates, nrow(db_i) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2) )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, (usable[i]/sum(table_i)))
}
Table_1 <- data.frame(table(db$Conservation_Action)) # Number of estimates
Table_1 <- data.frame(Table_1, n_studies,n_estimates,perc_testing,usable,unusable,perc_usable)
write.csv(Table_1,"Tables/Table_1.csv")
View(Table_1)
library("metafor")   # Meta-Analysis Package for R
library("ggplot2")
library("circlize")
View(Table_1)
View(Table_1)
table(db$Pearson_r_conversion)
db_metafor <- db[db$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
db_metafor
db_metafor
db_metafor <- db[db$Pearson_r_conversion == "converted",]
View(db_metafor)
View(db_metafor)
db_metafor <- db[db$Pearson_r_conversion == "converted",]
db_metafor <- db[db$Pearson_r_conversion == 'converted',]
rm(list = ls())
library("metafor")   # Meta-Analysis Package for R
library("ggplot2")
source("Functions/Functions_bat.R")
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
dec = '.',
header = TRUE,
as.is = FALSE
)
#Database only with distinct paper
db_unique <- distinct(db, ID, .keep_all = TRUE)
#Checking levels of factors
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Taxon_Group)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies    <- c()
n_estimates  <- c()
perc_testing <- c()
usable       <- c()
unusable     <- c()
perc_usable  <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates    <- c(n_estimates, nrow(db_i) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2) )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, (usable[i]/sum(table_i)))
}
Table_1 <- data.frame(table(db$Conservation_Action)) # Number of estimates
Table_1 <- data.frame(Table_1, n_studies,n_estimates,perc_testing,usable,unusable,perc_usable)
write.csv(Table_1,"Tables/Table_1.csv")
View(Table_1)
table(db_i$Pearson_r_conversion)
#Redefining impact
db$Impact2 <- db$Impact
levels(db$Impact2)
levels(db$Impact2)   <- c("Alien species\nPathogens",
"All",
"Climate\nchange",
"None",
"Alien species\nPathogens",
"Overexploitation\nPoaching",
"Pollution",
"Habitat change\n(subterranean)",
"Habitat change\n(surface)",
"Visitors")
db_metafor <- db[db$Pearson_r_conversion == "converted",]
View(db_metafor)
db_metafor <- droplevels(db_metafor)
str(db)
table(db$Pearson_r_conversion )
db_metafor <- db[db$Tested_statistically == "yes",]
View(db_metafor)
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
View(db_metafor)
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db_metafor
db_metafor %>% select(ID)
str(db_metafor)
db2 <- db_metafor %>% select(ID,
N,
Domain,
System
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db2 <- db_metafor %>% select(ID,
N,
Domain,
System,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
View(db2)
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
dec = '.',
header = TRUE,
as.is = FALSE
)
str(db)
View(db)
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
str(db)
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
header = TRUE,
as.is = FALSE
)
str(db)
db <-
read.csv(
file = "Data/database_bat_conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
str(db)
#Database only with distinct paper
db_unique <- distinct(db, ID, .keep_all = TRUE)
#Checking levels of factors
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Taxon_Group)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies    <- c()
n_estimates  <- c()
perc_testing <- c()
usable       <- c()
unusable     <- c()
perc_usable  <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates    <- c(n_estimates, nrow(db_i) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2) )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, (usable[i]/sum(table_i)))
}
Table_1 <- data.frame(table(db$Conservation_Action)) # Number of estimates
Table_1 <- data.frame(Table_1, n_studies, n_estimates, perc_testing, usable, unusable, perc_usable)
write.csv(Table_1,"Tables/Table_1.csv")
#Redefining impact
db$Impact2 <- db$Impact
levels(db$Impact2)   <- c("Alien species\nPathogens",
"All",
"Climate\nchange",
"None",
"Alien species\nPathogens",
"Overexploitation\nPoaching",
"Pollution",
"Habitat change\n(subterranean)",
"Habitat change\n(surface)",
"Visitors")
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db2 <- db_metafor %>% select(ID,
N,
Domain,
System,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
data_citation <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
data_citation <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
data_citation
