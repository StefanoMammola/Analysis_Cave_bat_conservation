ros_N <- c(ros_N,Ros_i$fsnum)
ros   <- c(ros,round(Ros_i$pval,3))
message(paste("---", predictors_to_analyse[[i]], "---", sep = ' '))
print(Ros_i) #Rosenthal's failsafe number (rule-of-thumb: it should be larger than n*5 + 10)
}
ros_N <- c()
ros   <- c()
for (i in 1:length(actions_to_analyse)){
Ros_i <- fsn(yi, vi, type = "Rosenthal", data = SUBSET[[i]])
ros_N <- c(ros_N,Ros_i$fsnum)
ros   <- c(ros,round(Ros_i$pval,3))
message(paste("---", predictors_to_analyse[[i]], "---", sep = ' '))
print(Ros_i) #Rosenthal's failsafe number (rule-of-thumb: it should be larger than n*5 + 10)
}
ros_N <- c()
ros   <- c()
for (i in 1:length(actions_to_analyse)){
Ros_i <- fsn(yi, vi, type = "Rosenthal", data = SUBSET[[i]])
ros_N <- c(ros_N,Ros_i$fsnum)
ros   <- c(ros,round(Ros_i$pval,3))
message(paste("---", actions_to_analyse[[i]], "---", sep = ' '))
print(Ros_i) #Rosenthal's failsafe number (rule-of-thumb: it should be larger than n*5 + 10)
}
library(tidyr)
library(ggpubr)
library(rstatix)
setwd("/Users/stefanomammola/Desktop/thefinalfigure")
data <- read.csv("ANOVA_cum_dist.csv")
class(data)
View(data)
data %>% sample_n_by(Sex, size = 1)
data <- data %>%
gather(key = "Time", value = "cum_dis", pre_cum_dist, gun_cum_dis, post_cum_dist) %>%
convert_as_factor(id, Time)
# Inspect some random rows of the data by groups
set.seed(123)
data %>% sample_n_by(Sex,Time, size = 1)
data %>%
group_by(Time) %>%
get_summary_stats(cum_dis, type = "mean_sd")
bxp1 <- ggboxplot(
data, x = "Time", y = "cum_dis", palette = "jco")
bxp1
data %>%
group_by(Time) %>%
identify_outliers(cum_dis)
data2<-subset(data, id!="F82")
data2
class(data2)
class(data2$id)
class(data2$Time)
#check normality
ggqqplot(data2, "cum_dis", ggtheme = theme_bw()) +
facet_grid("Time")
#Let's run a one-way within subjects ANOVA
anova <- anova_test(data = data2, dv = cum_dis, wid = id, within = Time)
get_anova_table(anova)
#pairwise comparisons
pwc <- data2 %>%
pairwise_t_test(
cum_dis ~ Time, paired = TRUE,
p.adjust.method = "bonferroni"
)
pwc
bxp3 <- ggboxplot(data2, x = "Time", y = "cum_dis", add = "point")
bxp3
data2 %>%
group_by(Time) %>%
get_summary_stats(cum_dis, type = "mean_sd")
pwc <- pwc %>% add_xy_position(x = "Time")
bxp +
stat_pvalue_manual(pwc) +
labs(
subtitle = get_test_label(anova, detailed = TRUE),
caption = get_pwc_label(pwc)
)
stat_pvalue_manual
cum_dis
bxp3
rm(list = ls())
# Loading R package -------------------------------------------------------
library("metafor")   # Meta-Analysis Package for R
library("ggplot2")
library("tidyverse")
library("circlize")
library("cowplot")
library("dplyr")
library("ggplot2")
library("ggpubr")
library("grid")
library("gridExtra")
library("maps")
library("rsq")
library("parameters")
library("performance")
library("scatterpie")
library("tidyr")
# Sourcing useful functions ------------------------------------------------
source("Functions/Functions_bat.R")
###############################################################
## Data preparation:
###############################################################
# Loading the Database ----------------------------------------------------
db_full <-
read.csv(
file = "Data/Master_Database_Cave_Conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
#Subselecting BAT studies
db <- db_full[db_full$Bat_analysis == "yes",] ; db <- droplevels(db)
db$N <- as.numeric(db$N)
# How many study consider bats and other groups?
a <- ifelse(table(db$ID, db$Taxon_Group)>0,1,0)
table(rowSums(a))
sum(table(rowSums(a))[c(2,3)])/sum(table(rowSums(a)))*100 #3.5 % of studies consider multiple organisms
# Selecting only bats
db <- db[db$Taxon_Group == "Bats",] ; db <- droplevels(db)
#Database only with distinct paper
db_unique <- distinct(db, ID, .keep_all = TRUE)
#Checking levels of factors
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Taxon_Group)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Type of actions
table(db$Publication_type)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies    <- c()
n_estimates  <- c()
perc_testing <- c()
usable       <- c()
unusable     <- c()
perc_usable  <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates    <- c(n_estimates, nrow(db_i) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_1 <- data.frame(Intervention = levels(db$Conservation_Action), n_studies, n_estimates, perc_testing, usable, unusable, perc_usable)
Table_1[is.na(Table_1)] <- 0
colnames(Table_1) <- c("Intervention", "N° studies", "N° interventions", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_1,"Tables/Table_1.csv")
#Redefining impact
db$Impact2 <- db$Impact
levels(db$Impact)[2] <- "Multiple"
levels(db$Impact)[8] <- "Subterranean\nhabitat change"
levels(db$Impact)[9] <- "Surface\nhabitat change"
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
# Gate
db_metafor <- db_metafor[db_metafor$Predictor_Group == "Gate" | db_metafor$Predictor_Group == "Disturbance reduction",] ; db_metafor <- droplevels(db_metafor)
#Check sample size for each predictors
table_n <- data.frame(predictor = NULL, n = NULL, n_papers = NULL)
for(i in 1:length(unique(levels(db_metafor$Response_Group))))
table_n <- rbind(table_n,
data.frame(predictor = levels(db_metafor$Response_Group)[i],
n = nrow(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]),
n_papers = length(unique(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]$ID)))
)
actions_to_analyse    <- c("Gate", "Disturbance reduction")
SUBSET    <- list()
MODEL     <- list()
result_for_plot <- data.frame(label_action = NULL,
label_pred = NULL,
size = NULL,
b     = NULL,
ci.lb = NULL,
ci.ub = NULL,
ES    = NULL,
L     = NULL,
U     = NULL)
# Modelling
for (j in 1:length(actions_to_analyse)){
data_j  <- db_metafor[db_metafor$Predictor_Group == actions_to_analyse[j], ] ; data_j <- droplevels(data_j)
predictors_to_analyse <- levels(data_j$Response_Group)
for (i in 1:length(predictors_to_analyse)){
#subset the predictor
data_i  <- data_j[data_j$Response_Group == predictors_to_analyse[i], ]
#fitting the model
model_i <- rma.mv(yi, vi, random =  ~ 1 | ID, data = na.omit(data_i))
#extracting coefficients
result_for_plot_i <- data.frame(label_action =  actions_to_analyse[j],
label_pred = paste(predictors_to_analyse[i]," (" ,
nrow(data_i),", ",
length(unique(data_i$ID)),")",sep=''),
size = length(unique(data_i$ID)),
b     = model_i$b,
ci.lb = model_i$ci.lb,
ci.ub = model_i$ci.ub,
ES    = ((exp(model_i$b)-1))/((exp(model_i$b)+1)),
L     = ((exp(model_i$ci.lb)-1)/(exp(model_i$ci.lb)+1)),
U     = ((exp(model_i$ci.ub)-1)/(exp(model_i$ci.ub)+1)))
#store the data
SUBSET[[i]]     <- data_i
MODEL[[i]]      <- model_i
result_for_plot <- rbind(result_for_plot,result_for_plot_i)
}
}
rownames(result_for_plot) <- NULL
rm(list = ls())
library("metafor")   # Meta-Analysis Package for R
library("ggplot2")
library("tidyverse")
library("circlize")
library("cowplot")
library("dplyr")
library("ggplot2")
library("ggpubr")
library("grid")
library("gridExtra")
library("maps")
library("rsq")
library("parameters")
library("performance")
library("scatterpie")
library("tidyr")
source("Functions/Functions_bat.R")
db_full <-
read.csv(
file = "Data/Master_Database_Cave_Conservation.csv",
sep = '\t',
dec = ',',
header = TRUE,
as.is = FALSE
)
db <- db_full[db_full$Bat_analysis == "yes",] ; db <- droplevels(db)
db$N <- as.numeric(db$N)
a <- ifelse(table(db$ID, db$Taxon_Group)>0,1,0)
table(rowSums(a))
sum(table(rowSums(a))[c(2,3)])/sum(table(rowSums(a)))*100 #3.5 % of studies consider multiple organisms
# Selecting only bats
db <- db[db$Taxon_Group == "Bats",] ; db <- droplevels(db)
#Database only with distinct paper
db_unique <- distinct(db, ID, .keep_all = TRUE)
#Checking levels of factors
levels(db$Taxon_Group)
levels(db$Tested_statistically)
levels(db$Higher_Geography)
levels(db$System)
levels(db$Domain)
levels(db$Taxon_Group)
levels(db$Impact)
levels(db$Conservation_Group)
levels(db$Conservation_Action)
#Type of actions
table(db$Publication_type)
#Summary statistics (Literature)
table(db_unique$Source) ; sum(table(db_unique$Source)) # N° of unique sources
mean(table(db$ID)) ; SE(table(db$ID)) # mean number of actions/paper
#Summary statistics (Testing)
table(db$Tested_statistically)[2] / sum(table(db$Tested_statistically)) #N° and % testing
#How many estimates would be usable for meta analysis?
n_studies    <- c()
n_estimates  <- c()
perc_testing <- c()
usable       <- c()
unusable     <- c()
perc_usable  <- c()
for(i in 1:nlevels(db$Conservation_Action)){
db_i_tot <- db[db$Conservation_Action == levels(db$Conservation_Action)[i],]
db_i     <- db_i_tot[db_i_tot$Tested_statistically == "yes",]
table_i        <- table(db_i$Pearson_r_conversion) #% of usable statistics
n_studies      <- c(n_studies, nrow(distinct(db_i, ID, .keep_all = TRUE)) ) #unique studies
n_estimates    <- c(n_estimates, nrow(db_i) ) #unique estimates
perc_testing   <- c(perc_testing, round(nrow(db_i)/nrow(db_i_tot),2)*100 )
usable         <- c(usable, sum(table_i[1],table_i[3]))
unusable       <- c(unusable, sum(table_i[2]))
perc_usable    <- c(perc_usable, round((usable[i]/sum(table_i)),2)*100)
}
Table_1 <- data.frame(Intervention = levels(db$Conservation_Action), n_studies, n_estimates, perc_testing, usable, unusable, perc_usable)
Table_1[is.na(Table_1)] <- 0
colnames(Table_1) <- c("Intervention", "N° studies", "N° interventions", "% testing", "N° usable", "N° unusable", "% usable")
write.csv(Table_1,"Tables/Table_1.csv")
#Redefining impact
db$Impact2 <- db$Impact
levels(db$Impact)[2] <- "Multiple"
levels(db$Impact)[8] <- "Subterranean\nhabitat change"
levels(db$Impact)[9] <- "Surface\nhabitat change"
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
db_metafor
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
db_metafor <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
# Gate
db_metafor <- db_metafor[db_metafor$Predictor_Group == "Gate" | db_metafor$Predictor_Group == "Disturbance reduction",] ; db_metafor <- droplevels(db_metafor)
#Check sample size for each predictors
table_n <- data.frame(predictor = NULL, n = NULL, n_papers = NULL)
for(i in 1:length(unique(levels(db_metafor$Response_Group))))
table_n <- rbind(table_n,
data.frame(predictor = levels(db_metafor$Response_Group)[i],
n = nrow(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]),
n_papers = length(unique(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]$ID)))
)
actions_to_analyse    <- c("Gate", "Disturbance reduction")
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
db_metafor <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
# Gate
db_metafor <- db_metafor[db_metafor$Predictor_Group == "Gate" | db_metafor$Predictor_Group == "Restoration" | db_metafor$Predictor_Group == "Disturbance reduction",] ; db_metafor <- droplevels(db_metafor)
#Check sample size for each predictors
table_n <- data.frame(predictor = NULL, n = NULL, n_papers = NULL)
for(i in 1:length(unique(levels(db_metafor$Response_Group))))
table_n <- rbind(table_n,
data.frame(predictor = levels(db_metafor$Response_Group)[i],
n = nrow(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]),
n_papers = length(unique(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]$ID)))
)
actions_to_analyse    <- c("Gate", "Disturbance reduction", "Restoration")
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
db_metafor <- db[db$Tested_statistically == "yes",]
db_metafor <- db_metafor[db_metafor$Pearson_r_conversion == "converted",]
db_metafor <- droplevels(db_metafor)
dim(db_metafor) #2361 standardized estimates
nlevels(db_metafor$ID) #250 references
db_metafor <- db_metafor %>% select(ID,
N,
Domain,
System,
Family,
Response_Group,
Predictor_Group,
r = Pearson.s_r)
# Derive Fischer's Z and its variance
db_metafor <- escalc(measure = "ZCOR", ri = r, ni = N, data = db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
# Gate
db_metafor <- db_metafor[db_metafor$Predictor_Group == "Gate" | db_metafor$Predictor_Group == "Restoration" | db_metafor$Predictor_Group == "Disturbance reduction",] ; db_metafor <- droplevels(db_metafor)
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
#Check sample size for each predictors
table_n <- data.frame(predictor = NULL, n = NULL, n_papers = NULL)
for(i in 1:length(unique(levels(db_metafor$Response_Group))))
table_n <- rbind(table_n,
data.frame(predictor = levels(db_metafor$Response_Group)[i],
n = nrow(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]),
n_papers = length(unique(db_metafor[db_metafor$Response_Group == levels(db_metafor$Response_Group)[i], ]$ID)))
)
table_n
db_metafor$Predictor_Group
#Check sample size
table(db_metafor$Predictor_Group,db_metafor$Response_Group) # Disturbance reduction & Gate
db_metafor <- db_metafor[!c(db_metafor$Predictor_Group == "Disturbance reduction" & db_metafor$Response_Group =="Population"),]
actions_to_analyse    <- c("Gate", "Disturbance reduction", "Restoration")
db_metafor <- db_metafor[db_metafor$]
SUBSET    <- list()
MODEL     <- list()
result_for_plot <- data.frame(label_action = NULL,
label_pred = NULL,
size = NULL,
b     = NULL,
ci.lb = NULL,
ci.ub = NULL,
ES    = NULL,
L     = NULL,
U     = NULL)
# Modelling
for (j in 1:length(actions_to_analyse)){
data_j  <- db_metafor[db_metafor$Predictor_Group == actions_to_analyse[j], ] ; data_j <- droplevels(data_j)
predictors_to_analyse <- levels(data_j$Response_Group)
for (i in 1:length(predictors_to_analyse)){
#subset the predictor
data_i  <- data_j[data_j$Response_Group == predictors_to_analyse[i], ]
#fitting the model
model_i <- rma.mv(yi, vi, random =  ~ 1 | ID, data = na.omit(data_i))
#extracting coefficients
result_for_plot_i <- data.frame(label_action =  actions_to_analyse[j],
label_pred = paste(predictors_to_analyse[i]," (" ,
nrow(data_i),", ",
length(unique(data_i$ID)),")",sep=''),
size = length(unique(data_i$ID)),
b     = model_i$b,
ci.lb = model_i$ci.lb,
ci.ub = model_i$ci.ub,
ES    = ((exp(model_i$b)-1))/((exp(model_i$b)+1)),
L     = ((exp(model_i$ci.lb)-1)/(exp(model_i$ci.lb)+1)),
U     = ((exp(model_i$ci.ub)-1)/(exp(model_i$ci.ub)+1)))
#store the data
SUBSET[[i]]     <- data_i
MODEL[[i]]      <- model_i
result_for_plot <- rbind(result_for_plot,result_for_plot_i)
}
}
rownames(result_for_plot) <- NULL
(meta_analysis <- ggplot(data= result_for_plot) +
geom_hline(yintercept = 0, lty = 2, col = "grey50") +  # add a dotted line at x=1 after flip
xlab("")+
ylab("Effect size [r]")+
geom_pointrange(aes(x=label_pred, y=ES, ymin=L, ymax=U, col= label_action, size = ), size= .5) +
scale_color_manual(values = c("darkmagenta","grey10"))+
coord_flip() +
theme_custom() +
theme(axis.text.y = element_text(face= c("plain","bold","plain","bold","plain")))) # flip coordinates (puts labels on y axis)
(meta_analysis <- ggplot(data= result_for_plot) +
geom_hline(yintercept = 0, lty = 2, col = "grey50") +  # add a dotted line at x=1 after flip
xlab("")+
ylab("Effect size [r]")+
geom_pointrange(aes(x=label_pred, y=ES, ymin=L, ymax=U, col= label_action, size = ), size= .5) +
scale_color_manual(values = c("darkmagenta","grey10", "Turquoise"))+
coord_flip() +
theme_custom() +
theme(axis.text.y = element_text(face= c("plain","bold","plain","bold","plain")))) # flip coordinates (puts labels on y axis)
(meta_analysis <- ggplot(data= result_for_plot) +
geom_hline(yintercept = 0, lty = 2, col = "grey50") +  # add a dotted line at x=1 after flip
xlab("")+
ylab("Effect size [r]")+
geom_pointrange(aes(x=label_pred, y=ES, ymin=L, ymax=U, col= label_action, size = ), size= .5) +
scale_color_manual(values = c("darkmagenta","grey10", "Cyan"))+
coord_flip() +
theme_custom() +
theme(axis.text.y = element_text(face= c("plain","bold","plain","bold","plain")))) # flip coordinates (puts labels on y axis)
(meta_analysis <- ggplot(data= result_for_plot) +
geom_hline(yintercept = 0, lty = 2, col = "grey50") +  # add a dotted line at x=1 after flip
xlab("")+
ylab("Effect size [r]")+
geom_pointrange(aes(x=label_pred, y=ES, ymin=L, ymax=U, col= label_action, size = ), size= .5) +
scale_color_manual(values = c("darkmagenta","grey10", "darkcyan"))+
coord_flip() +
theme_custom() +
theme(axis.text.y = element_text(face= c("plain","bold","plain","bold","plain")))) # flip coordinates (puts labels on y axis)
#Save figure
pdf(file = "Figure/Figure_XX.pdf", width = 7, height =5)
meta_analysis
dev.off()
result_for_plot
db_metafor
## Tested statistically by Impact
bar_1 <- data.frame(table(db$Tested_statistically,db$Impact2))
levels(bar_1$Var2)[2] <- "Multiple"
#summary stats
table(db$Impact2) # tot
table(db$Impact2)/ sum(table(db$Impact2)) # %
bar_1$Var2 <- factor(bar_1$Var2,levels = c("Alien species\nPathogens","Climate\nchange","Overexploitation\nPoaching",
"Pollution","Habitat change\n(subterranean)","Habitat change\n(surface)",
"Visitors", "Multiple", "None"))
(bar_p1 <-  ggplot(bar_1, aes(x=Var2,y=Freq, fill=Var1)) +
geom_bar(stat="identity",position=position_dodge(), color = "grey20")+
geom_text(aes(label=Freq), vjust=-1, color="black",
position = position_dodge(0.9), size=2.5)+
ylim(0,320)+
scale_fill_manual("",labels=c("Not tested", "Tested"),values=col_fig2)+
labs(title=NULL, subtitle = NULL,x=NULL, y = "Frequency")+
theme_custom()+
theme(legend.position =  "none",
axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
plot.margin = unit(c(0.2,0.2,0.2,0.2), 'cm'))
)
## Tested statistically by System
bar_3 <- semi_colon_splitter(input1 = db$System,
input2 = db$Tested_statistically,
names = c("System","Tested_statistically"))
